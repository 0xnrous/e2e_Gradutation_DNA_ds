{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## last vectorizer\n",
    "- error of ValueError: could not convert string to float:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_pickle(\"../data/processed/final_processed_data.pkl\")\n",
    "# Convert DNA sequence columns to string type\n",
    "df['Parent_full_DNA_Seq'] = df['Parent_full_DNA_Seq'].astype(str)\n",
    "df['Child_full_DNA_Seq'] = df['Child_full_DNA_Seq'].astype(str)\n",
    "# Load vectorizer as kmer\n",
    "vectorizer = joblib.load('../data/interim/kmer_model.sav')\n",
    "# Select relevant columns\n",
    "df_pre = df[['Parent_full_DNA_Seq','Child_full_DNA_Seq','target']]\n",
    "# Split data into train and test sets\n",
    "x = df_pre.drop('target', axis=1)\n",
    "y = df_pre['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Define transformer for k-mer embedding\n",
    "class KmerEmbeddingTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vectorizer):\n",
    "        self.vectorizer = vectorizer\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        X_ch = self.vectorizer.fit_transform(X_copy['Child_full_DNA_Seq'])\n",
    "        X_p = self.vectorizer.fit_transform(X_copy['Parent_full_DNA_Seq'])\n",
    "        kmer_embeddings_c = X_ch.toarray()\n",
    "        kmer_embeddings_p = X_p.toarray()\n",
    "        kmer_embeddings_p = np.pad(kmer_embeddings_p, ((0, 0), (0, 1)), 'constant')\n",
    "        for i in range(len(kmer_embeddings_c[0])):\n",
    "            column_name_child = 'child_gene_k_' + str(i)\n",
    "            column_name_parent = 'parent_gene_k_' + str(i)\n",
    "            X_copy[column_name_child] = [kmer_embeddings_c[j][i] for j in range(len(X_copy))]\n",
    "            X_copy[column_name_parent] = [kmer_embeddings_p[j][i] for j in range(len(X_copy))]\n",
    "        return X_copy\n",
    "\n",
    "# Define custom transformer to drop specific columns\n",
    "class DropSpecificColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns_to_drop):\n",
    "        self.columns_to_drop = columns_to_drop\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        for column in self.columns_to_drop:\n",
    "            if column in X_copy.columns:\n",
    "                X_copy.drop(column, axis=1, inplace=True)\n",
    "        return X_copy\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('kmer_embedding', KmerEmbeddingTransformer(vectorizer)),\n",
    "    ('drop_specific_columns', DropSpecificColumns(columns_to_drop=['child_gene_k_64', 'parent_gene_k_64'])),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('model', XGBClassifier(\n",
    "        learning_rate=0.3,\n",
    "        n_estimators=15000,\n",
    "        max_depth=15\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Fit the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Save the pipeline\n",
    "joblib.dump(pipeline, 'kmer_embedding_pipeline.pkl')\n",
    "\n",
    "# Load the pipeline\n",
    "pipeline_loaded = joblib.load('kmer_embedding_pipeline.pkl')\n",
    "\n",
    "# Predictions\n",
    "y_pred_test = pipeline.predict(X_test)\n",
    "# Evaluate the model\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_test)\n",
    "\n",
    "# 25 min to run test/ 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X_copy: 40938\n",
      "Length of kmer_embeddings_c: 40938\n",
      "Length of kmer_embeddings_p: 40938\n",
      "Length of X_train: 40938\n",
      "Length of X_test: 11757\n",
      "Length of y_train: 40938\n",
      "Length of y_test: 11757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3z/w_2xtxjs7517xwd76c815h5c0000gn/T/ipykernel_75934/3107340636.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_copy[f'parent_gene_k_{i}'] = [self.kmer_embeddings_p[j][i] for j in range(len(X_copy))]\n",
      "/var/folders/3z/w_2xtxjs7517xwd76c815h5c0000gn/T/ipykernel_75934/3107340636.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_copy[f'child_gene_k_{i}'] = [self.kmer_embeddings_c[j][i] for j in range(len(X_copy))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X_copy: 11757\n",
      "Length of kmer_embeddings_c: 40938\n",
      "Length of kmer_embeddings_p: 40938\n",
      "Length of X_train: 40938\n",
      "Length of X_test: 11757\n",
      "Length of y_train: 40938\n",
      "Length of y_test: 11757\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "# Import necessary libraries\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_pickle(\"../data/processed/final_processed_data.pkl\")\n",
    "\n",
    "# Convert DNA sequence columns to string type\n",
    "df['Parent_full_DNA_Seq'] = df['Parent_full_DNA_Seq'].astype(str)\n",
    "df['Child_full_DNA_Seq'] = df['Child_full_DNA_Seq'].astype(str)\n",
    "\n",
    "# Load vectorizer as kmer\n",
    "vectorizer = joblib.load('../data/interim/kmer_model.sav')\n",
    "\n",
    "# Load precomputed k-mer embeddings for training data\n",
    "kmer_embeddings_c = np.load('../data/interim/train_vectorizer_np/kmer_embeddings_c1.npy')\n",
    "kmer_embeddings_p = np.load('../data/interim/train_vectorizer_np/kmer_embeddings_p1.npy')\n",
    "\n",
    "# Select relevant columns\n",
    "df_pre = df[['Parent_full_DNA_Seq', 'Child_full_DNA_Seq', 'target']]\n",
    "\n",
    "# Split data into train and test sets\n",
    "x = df_pre.drop('target', axis=1)\n",
    "y = df_pre['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train[:len(kmer_embeddings_c)]\n",
    "y_train = y_train[:len(kmer_embeddings_c)]\n",
    "\n",
    "\n",
    "# Truncate k-mer embeddings arrays\n",
    "kmer_embeddings_c_truncated = kmer_embeddings_c[:len(X_train)]\n",
    "kmer_embeddings_p_truncated = kmer_embeddings_p[:len(X_train)]\n",
    "\n",
    "\n",
    "# Define transformer for k-mer embedding\n",
    "class KmerEmbeddingTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, kmer_embeddings_c, kmer_embeddings_p):\n",
    "        self.kmer_embeddings_c = kmer_embeddings_c\n",
    "        self.kmer_embeddings_p = kmer_embeddings_p\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        max_length = min(len(X_copy), len(self.kmer_embeddings_c))\n",
    "        X_copy = X_copy.iloc[:max_length]\n",
    "# Check the length of X_copy\n",
    "        print(\"Length of X_copy:\", len(X_copy))\n",
    "\n",
    "        # Check the length of kmer_embeddings_c and kmer_embeddings_p\n",
    "        print(\"Length of kmer_embeddings_c:\", len(kmer_embeddings_c))\n",
    "        print(\"Length of kmer_embeddings_p:\", len(kmer_embeddings_p))\n",
    "\n",
    "        # Check the consistency of train-test split\n",
    "        print(\"Length of X_train:\", len(X_train))\n",
    "        print(\"Length of X_test:\", len(X_test))\n",
    "        print(\"Length of y_train:\", len(y_train))\n",
    "        print(\"Length of y_test:\", len(y_test))\n",
    "\n",
    "        \n",
    "        for i in range(len(self.kmer_embeddings_c[0])):\n",
    "            X_copy[f'child_gene_k_{i}'] = [self.kmer_embeddings_c[j][i] for j in range(len(X_copy))]\n",
    "            X_copy[f'parent_gene_k_{i}'] = [self.kmer_embeddings_p[j][i] for j in range(len(X_copy))]\n",
    "        return X_copy\n",
    "# Define custom transformer to drop specific columns\n",
    "class DropSpecificColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns_to_drop):\n",
    "        self.columns_to_drop = columns_to_drop\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        for column in self.columns_to_drop:\n",
    "            if column in X_copy.columns:\n",
    "                X_copy.drop(column, axis=1, inplace=True)\n",
    "        return X_copy\n",
    "    \n",
    "    \n",
    "\n",
    "# Transform data using KmerEmbeddingTransformer\n",
    "kmer_transformer = KmerEmbeddingTransformer(kmer_embeddings_c_truncated, kmer_embeddings_p_truncated)\n",
    "X_train_transformed = kmer_transformer.fit_transform(X_train)\n",
    "X_test_transformed = kmer_transformer.transform(X_test)\n",
    "\n",
    "# Drop 'Parent_full_DNA_Seq' and 'Child_full_DNA_Seq' columns\n",
    "X_train_transformed.drop(['Parent_full_DNA_Seq', 'Child_full_DNA_Seq'], axis=1, inplace=True)\n",
    "X_test_transformed.drop(['Parent_full_DNA_Seq', 'Child_full_DNA_Seq'], axis=1, inplace=True)\n",
    "\n",
    "# Drop specific columns\n",
    "column_dropper = DropSpecificColumns(columns_to_drop=['child_gene_k_64', 'parent_gene_k_64'])\n",
    "X_train_transformed = column_dropper.fit_transform(X_train_transformed)\n",
    "X_test_transformed = column_dropper.transform(X_test_transformed)\n",
    "\n",
    "# # Define the main pipeline with preprocessing steps\n",
    "# pipeline = Pipeline([\n",
    "#     ('scaler', MinMaxScaler()),\n",
    "#     ('model', SVC(kernel='rbf', C=0.5, gamma='scale'))\n",
    "# ])                                          \n",
    "                                              \n",
    "# Define the main pipeline with preprocessing steps\n",
    "pipeline = Pipeline([\n",
    "    # ('preprocessor', preprocessor),  # Preprocess DNA sequences\n",
    "    #('kmer_embedding', KmerEmbeddingTransformer(kmer_embeddings_c, kmer_embeddings_p)),\n",
    "    #('drop_specific_columns', DropSpecificColumns(columns_to_drop=['child_gene_k_64', 'parent_gene_k_64'])),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('model', XGBClassifier(\n",
    "        learning_rate=0.3,\n",
    "        n_estimators=15000,\n",
    "        max_depth=15\n",
    "    ))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fit the pipeline using transformed data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_transformed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Save the pipeline\u001b[39;00m\n\u001b[1;32m      4\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(pipeline, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkmer_embedding_pipeline.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py:427\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    426\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 427\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1490\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1462\u001b[0m (\n\u001b[1;32m   1463\u001b[0m     model,\n\u001b[1;32m   1464\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1470\u001b[0m )\n\u001b[1;32m   1471\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1472\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1473\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1488\u001b[0m )\n\u001b[0;32m-> 1490\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1505\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit the pipeline using transformed data\n",
    "pipeline.fit(X_train_transformed, y_train)\n",
    "# Save the pipeline\n",
    "joblib.dump(pipeline, 'kmer_embedding_pipeline.pkl')\n",
    "\n",
    "# # Load the pipeline\n",
    "pipeline_loaded = joblib.load('kmer_embedding_pipeline.pkl')\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_test = pipeline.predict(X_test_transformed)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Test Accuracy:\", accuracy_test)\n",
    "\n",
    "#time 4 min 10 sec\n",
    "# Test Accuracy: 0.6273709279578124 / test 1 / SVM\n",
    "# ------------------------------------\n",
    "#time 31 min 34 sec \n",
    "# Test Accuracy: 0.5374670409117972 / test 2  / XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3z/w_2xtxjs7517xwd76c815h5c0000gn/T/ipykernel_75934/3353159167.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_copy[f'parent_gene_k_{i}'] = [self.kmer_embeddings_p[j][i] for j in range(len(X_copy))]\n",
      "/var/folders/3z/w_2xtxjs7517xwd76c815h5c0000gn/T/ipykernel_75934/3353159167.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_copy[f'child_gene_k_{i}'] = [self.kmer_embeddings_c[j][i] for j in range(len(X_copy))]\n",
      "/var/folders/3z/w_2xtxjs7517xwd76c815h5c0000gn/T/ipykernel_75934/3353159167.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_copy[f'parent_gene_k_{i}'] = [self.kmer_embeddings_p[j][i] for j in range(len(X_copy))]\n",
      "/var/folders/3z/w_2xtxjs7517xwd76c815h5c0000gn/T/ipykernel_75934/3353159167.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_copy[f'child_gene_k_{i}'] = [self.kmer_embeddings_c[j][i] for j in range(len(X_copy))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6268273916388818\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_pickle(\"../data/processed/final_processed_data.pkl\")\n",
    "df.drop(df.tail(100).index,inplace=True)\n",
    "\n",
    "# Convert DNA sequence columns to string type\n",
    "df['Parent_full_DNA_Seq'] = df['Parent_full_DNA_Seq'].astype(str)\n",
    "df['Child_full_DNA_Seq'] = df['Child_full_DNA_Seq'].astype(str)\n",
    "\n",
    "# Load precomputed k-mer embeddings for training data\n",
    "kmer_embeddings_c = np.load('../data/interim/train_vectorizer_np/kmer_embeddings_c1.npy')\n",
    "kmer_embeddings_p = np.load('../data/interim/train_vectorizer_np/kmer_embeddings_p1.npy')\n",
    "\n",
    "# Select relevant columns\n",
    "df_pre = df[['Parent_full_DNA_Seq', 'Child_full_DNA_Seq', 'target']]\n",
    "\n",
    "# Split data into train and test sets\n",
    "x = df_pre.drop('target', axis=1)\n",
    "y = df_pre['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train[:len(kmer_embeddings_c)]\n",
    "y_train = y_train[:len(kmer_embeddings_c)]\n",
    "\n",
    "# Define transformer for k-mer embedding\n",
    "class KmerEmbeddingTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, kmer_embeddings_c, kmer_embeddings_p):\n",
    "        self.kmer_embeddings_c = kmer_embeddings_c\n",
    "        self.kmer_embeddings_p = kmer_embeddings_p\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        max_length = min(len(X_copy), len(self.kmer_embeddings_c))\n",
    "        X_copy = X_copy.iloc[:max_length]\n",
    "\n",
    "        for i in range(len(self.kmer_embeddings_c[0])):\n",
    "            X_copy[f'child_gene_k_{i}'] = [self.kmer_embeddings_c[j][i] for j in range(len(X_copy))]\n",
    "            X_copy[f'parent_gene_k_{i}'] = [self.kmer_embeddings_p[j][i] for j in range(len(X_copy))]\n",
    "        return X_copy\n",
    "\n",
    "# Define custom transformer to drop specific columns\n",
    "class DropSpecificColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns_to_drop):\n",
    "        self.columns_to_drop = columns_to_drop\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.drop(self.columns_to_drop, axis=1, errors='ignore').copy()\n",
    "\n",
    "# Define the main pipeline with preprocessing and model training steps\n",
    "#----------------------------------------------------------------------------------\n",
    "# PIPELINE for XGB Classifier\n",
    "#----------------------------------------------------------------------------------\n",
    "# pipeline = Pipeline([\n",
    "#     ('kmer_transformer', KmerEmbeddingTransformer(kmer_embeddings_c, kmer_embeddings_p)),\n",
    "#     ('drop_columns', DropSpecificColumns(columns_to_drop=['Parent_full_DNA_Seq', 'Child_full_DNA_Seq'])),\n",
    "#     ('scaler', MinMaxScaler()),\n",
    "#     ('model', XGBClassifier(\n",
    "#         learning_rate=0.3,\n",
    "#         n_estimators=15000,\n",
    "#         max_depth=15\n",
    "#     ))\n",
    "# ])\n",
    "\n",
    "# Test Accuracy: 0.5411244365059114 / test 1 / XGBClassifier\n",
    "# Time 34 min 10 sec\n",
    "#----------------------------------------------------------------------------------\n",
    "# PIPELINE for SVM Classifier\n",
    "#----------------------------------------------------------------------------------\n",
    "pipeline = Pipeline([\n",
    "    ('kmer_transformer', KmerEmbeddingTransformer(kmer_embeddings_c, kmer_embeddings_p)),\n",
    "    ('drop_columns', DropSpecificColumns(columns_to_drop=['Parent_full_DNA_Seq', 'Child_full_DNA_Seq'])),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('model', SVC(kernel='rbf', C=0.5, gamma='scale'))\n",
    "    \n",
    "])\n",
    "\n",
    "# Test Accuracy: 0.6268273916388818 / test 2 / SVM\n",
    "# Time 4 min 10 sec\n",
    "#----------------------------------------------------------------------------------\n",
    "\n",
    "# Fit the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_test = pipeline.predict(X_test)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Test Accuracy:\", accuracy_test)\n",
    "\n",
    "# # Save the pipeline\n",
    "# joblib.dump(pipeline, 'kmer_embedding_pipeline.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:: 62.68%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy:: {accuracy_test * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Step 1: Data Loading\n",
    "df = pd.read_pickle(\"../data/processed/final_processed_data.pkl\")\n",
    "df.drop(df.tail(100).index, inplace=True)\n",
    "\n",
    "# Step 2: Data Preprocessing\n",
    "# Convert DNA sequence columns to string type\n",
    "df['Parent_full_DNA_Seq'] = df['Parent_full_DNA_Seq'].astype(str)\n",
    "df['Child_full_DNA_Seq'] = df['Child_full_DNA_Seq'].astype(str)\n",
    "\n",
    "# Load precomputed k-mer embeddings for training data\n",
    "kmer_embeddings_c = np.load('../data/interim/train_vectorizer_np/kmer_embeddings_c1.npy')\n",
    "kmer_embeddings_p = np.load('../data/interim/train_vectorizer_np/kmer_embeddings_p1.npy')\n",
    "\n",
    "# Select relevant columns\n",
    "df_pre = df[['Parent_full_DNA_Seq', 'Child_full_DNA_Seq', 'target']]\n",
    "\n",
    "# Split data into train and test sets\n",
    "x = df_pre.drop('target', axis=1)\n",
    "y = df_pre['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train[:len(kmer_embeddings_c)]\n",
    "y_train = y_train[:len(kmer_embeddings_c)]\n",
    "\n",
    "# Define a custom transformer to reshape data for CNN input\n",
    "class ReshapeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "# Step 3: Model Definition\n",
    "def create_cnn_model(input_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Step 4: Pipeline Integration\n",
    "cnn_pipeline = Pipeline([\n",
    "    ('reshape', ReshapeTransformer()),\n",
    "    ('scaler', MinMaxScaler()),  # Add any other preprocessing steps as needed\n",
    "    ('cnn', tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn=create_cnn_model, epochs=10, batch_size=32))\n",
    "])\n",
    "\n",
    "# # Step 5: Training\n",
    "# cnn_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# # Step 6: Evaluation\n",
    "# y_pred_test = cnn_pipeline.predict(X_test)\n",
    "# accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "# print(\"Test Accuracy:\", accuracy_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Training\n",
    "cnn_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Evaluation\n",
    "y_pred_test = cnn_pipeline.predict(X_test)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Test Accuracy:\", accuracy_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
